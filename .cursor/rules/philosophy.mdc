---
alwaysApply: true
---

# Philosophy & Vision

## Core Principles
1. **Local-first** - All inference runs on M3 256GB Mac Studio
2. **Dual-pipeline** - Text RAG (fast) + ColQwen (visual) stay separate
3. **Visual grounding** - BBoxes and page images are core, not optional
4. **Elysia patterns** - Decision tree, Environment state, Tool availability

## Current Architecture
```
User Query → Agent (Elysia-style)
           ├→ FastVectorSearch (AssetManual, ~0.5s)
           └→ ColQwenSearch (PDFDocuments, ~3s)
           → Environment stores results
           → LLM synthesizes answer (TODO)
```

## Target State (Dec 2025)

### Agent Evolution
- [ ] Rule-based routing → **Qwen3 with thinking mode**
- [ ] Mock responses → **MLX-powered generation**
- [ ] Keyword matching → **LLM decision with reasoning traces**

### Model Stack (MLX on M3 256GB)
| Role | Model | Active Params | Memory |
|------|-------|---------------|--------|
| Router | `Qwen3-30B-A3B-4bit` | 3B (MoE) | ~17GB |
| Synthesizer | `Qwen3-14B-4bit` | 14B | ~9GB |
| Vision | `Qwen2.5-VL-7B-4bit` | 7B | ~5GB |
| Retrieval | `ColQwen2.5-v0.2` | 2B | ~4GB |
| Embeddings | `nomic-embed-text` | - | Ollama |

Total: ~35GB loaded, 200GB+ for KV cache

### Key Upgrades
1. **MLX inference** - Native Apple Silicon, 4x faster TTFT
2. **Streaming synthesis** - Real token streaming, not mock
3. **Visual interpretation** - VLM reads ColQwen pages
4. **Self-healing errors** - Error objects inform retry logic

## Design Decisions

### Why Not Full Elysia?
- Need custom bbox/preview metadata
- Want MLX not LiteLLM
- Keep ColQwen multi-vector control

### What We Took from Elysia
- `Environment` for centralized state
- `Tool` base with `is_tool_available`, `run_if_true`
- `Result`/`Error` objects for typed outputs
- Decision transparency (reasoning exposed)

## Don't Over-Engineer
- No abstractions for one-time ops
- No future-proofing hypotheticals
- Fix the bug, don't refactor surroundings
- Minimum complexity for current task
