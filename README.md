# VSM - Visual Search Manual

A **hybrid agentic RAG system** for searching technical asset manuals with visual grounding. Supports both local (Mac Studio) and cloud (MacBook Air) deployment modes.

## Features

- ðŸ” **Dual RAG Pipelines**: Text search + Visual search (separate pipelines)
- ðŸ¤– **Agentic LLM**: DSPy-powered tool selection (model-agnostic)
- ðŸ“„ **Visual Grounding**: Bounding boxes overlay on page images
- âš¡ **Streaming Responses**: Real-time NDJSON output
- ðŸ”„ **Mode-Switchable**: `VSM_MODE=local|cloud` via Provider abstraction

## Deployment Modes

| Component | Local (Mac Studio) | Cloud (MacBook Air) |
|-----------|-------------------|---------------------|
| **LLM** | gpt-oss:120b (Ollama) | Gemini 2.5 Flash |
| **VLM** | Qwen3-VL-8B (MLX) | Gemini 2.5 Flash |
| **Embeddings** | bge-m3 (Ollama) | Jina v4 |
| **Visual Search** | ColQwen2.5-v0.2 | Weaviate + Jina CLIP v2 |
| **Vector DB** | Weaviate (Docker) | Weaviate Cloud |

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Mac Studio (Local Mode)                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚  Native Ollama  â”‚    â”‚  API (8001) / Frontend (3000)   â”‚â”‚
â”‚  â”‚  (0.0.0.0:11434)â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚  â”‚  - gpt-oss:120b â”‚                                       â”‚
â”‚  â”‚  - bge-m3       â”‚    host.docker.internal:11434         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â–¼                        â”‚
â”‚           â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ Weaviate (8080) â”‚ Docker           â”‚
â”‚                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  MacBook Air (Cloud Mode)                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚  API (8001) / Frontend (3000)                           â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚           â”‚                                                 â”‚
â”‚           â–¼                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Gemini API  â”‚  â”‚  Jina API   â”‚  â”‚  Weaviate Cloud   â”‚   â”‚
â”‚  â”‚ (LLM + VLM) â”‚  â”‚ (Embeddings)â”‚  â”‚ (+ Jina CLIP v2)  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Quick Start

### Prerequisites

- macOS with Apple Silicon (M1/M2/M3)
- Conda (with `vsm-hva` environment)
- **Local Mode**: [Ollama](https://ollama.ai), Docker Desktop
- **Cloud Mode**: API keys for Gemini, Jina, Weaviate Cloud

### Option A: Local Mode (Mac Studio)

```bash
./scripts/start.sh
```

### Option B: Cloud Mode (MacBook Air)

```bash
./scripts/start_cloud.sh
```

> **Note:** Cloud mode requires `.env` with `GEMINI_API_KEY`, `JINA_API_KEY`, `WEAVIATE_URL`, `WEAVIATE_API_KEY`

## Environment Variables

### Mode Selection

```bash
VSM_MODE=local   # Default: use Ollama + MLX + ColQwen
VSM_MODE=cloud   # Use Gemini + Jina + Weaviate Cloud
```

### Local Mode

```bash
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=gpt-oss:120b
OLLAMA_EMBED_MODEL=bge-m3
MLX_VLM_BASE_URL=http://localhost:8000
WEAVIATE_LOCAL_URL=http://localhost:8080
```

### Cloud Mode

```bash
GEMINI_API_KEY=AIza...
GEMINI_MODEL=gemini-2.5-flash
GEMINI_THINKING_BUDGET=-1  # -1=dynamic, 0=off, 1-24576=tokens
JINA_API_KEY=jina_...
WEAVIATE_URL=https://xxx.weaviate.cloud
WEAVIATE_API_KEY=xxx
```

## Ingesting Documents

### Local Mode

```bash
# Parse PDF with LandingAI ADE
python scripts/parse_with_landingai.py data/manual.pdf data/output.json

# Generate page previews
python scripts/generate_previews.py data/manual.pdf static/previews/manual

# Ingest text into Weaviate
python scripts/weaviate_ingest_manual.py data/output.json "Manual Name"

# Ingest visuals (ColQwen)
python scripts/colqwen_ingest.py "Manual Name"
```

### Cloud Mode

```bash
# Ingest both text and visuals to Weaviate Cloud
export VSM_MODE=cloud
python scripts/cloud_ingest.py --text data/output.json "Manual Name"
python scripts/cloud_ingest.py --visual data/manual.pdf "Manual Name"
```

## API Endpoints

| Endpoint | Description |
|----------|-------------|
| `GET /search?query=...` | Fast hybrid search |
| `GET /agentic_search?query=...` | Agentic streaming search (SSE) |
| `GET /healthz` | Health check |

## Project Structure

```
vsm-v02/
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ config.py           # Settings + VSM_MODE
â”‚   â”‚   â”œâ”€â”€ providers/          # LLM/VLM/Embed/VectorDB abstractions
â”‚   â”‚   â””â”€â”€ dspy_config.py      # DSPy LM configuration
â”‚   â”œâ”€â”€ prompts/                # DSPy signatures
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ agent.py            # Decision tree orchestrator
â”‚   â”‚   â””â”€â”€ tools/              # Tool implementations
â”‚   â””â”€â”€ endpoints/              # FastAPI routes
â”œâ”€â”€ frontend/                   # Next.js 16 + React 19
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ start.sh                # Start local services
â”‚   â”œâ”€â”€ stop.sh                 # Stop services
â”‚   â”œâ”€â”€ cloud_ingest.py         # Cloud ingestion
â”‚   â””â”€â”€ weaviate_ingest_manual.py
â”œâ”€â”€ docs/cloud-migration/       # Architecture docs
â””â”€â”€ static/previews/            # Page PNG images
```

## Models & Memory (Local Mode)

| Model | Size | Purpose |
|-------|------|---------|
| gpt-oss:120b | ~65GB | LLM (decisions + generation) |
| bge-m3 | ~1.2GB | Text embeddings (8K context) |
| ColQwen2.5-v0.2 | ~4GB | Visual retrieval |
| Qwen3-VL-8B | ~8GB | Visual interpretation (MLX) |

**Total**: ~78GB, leaving ~178GB for KV cache on 256GB Mac Studio.

## Troubleshooting

### "404 Not Found" for Ollama API (Local)

**Cause**: Wrong Ollama instance running (Docker instead of Native).

**Fix**: Run `./scripts/start.sh` - it automatically kills conflicting containers.

### Search returns 0 results (Cloud)

**Cause**: Data not ingested to cloud Weaviate.

**Fix**: Run `python scripts/cloud_ingest.py ...` to ingest data.

### "GEMINI_API_KEY not set" (Cloud)

**Cause**: Missing environment variables.

**Fix**: Ensure all cloud API keys are exported before starting.

## Logs

```bash
tail -f /tmp/vsm-ollama.log    # Ollama (local)
tail -f /tmp/vsm-api.log       # Backend API
tail -f /tmp/vsm-frontend.log  # Frontend
```

## Debugging Agent Issues

Query traces are auto-saved to `logs/query_traces/` for every `/agentic_search` call.

```bash
# 1. Find the trace
ls -la logs/query_traces/

# 2. Run intelligent analysis (uses Gemini 3 Pro's 1M context)
python scripts/analyze_with_llm.py --gemini-only <trace_id_prefix>
```

## Documentation

- [Cloud Migration Architecture](docs/cloud-migration/README.md)
- [Provider Layer Design](docs/cloud-migration/02-provider-layer.md)
- [Configuration Guide](docs/cloud-migration/06-configuration-guide.md)
- [Agent Flow Diagram](docs/agent_diagram.md)
- [RAG Pipeline Explained](docs/RAG_PIPELINE_EXPLAINED.md)

## Tech Stack

- **LLM**: gpt-oss:120b (local) / Gemini 2.5 Flash (cloud)
- **Embeddings**: bge-m3 (local) / Jina v4 (cloud)
- **Visual Search**: ColQwen2.5 (local) / Jina CLIP v2 (cloud)
- **Vector DB**: Weaviate 1.34
- **Backend**: Python 3.12, FastAPI, DSPy
- **Frontend**: Next.js 16, React 19, Tailwind v4
- **Parsing**: LandingAI ADE
